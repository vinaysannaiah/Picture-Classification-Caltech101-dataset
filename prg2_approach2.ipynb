################################# Import all the Libraries #########################################################

from sklearn.preprocessing import LabelEncoder # import LabelEncoder to encode labels with value between 0 and num_classes-1
from sklearn.preprocessing import MinMaxScaler # import MinMaxScaler to Transform features by scaling each feature to a given range
import numpy as np 
import mahotas
import cv2 # import open CV to read and convert the image from color to grayscale
import os # import os to read the files from a directory
import h5py # import h5py to create a data file 

####################################################################################################################

#################################### Initialize the required Variables ############################################

# fixed-sizes for image
fixed_size = (500, 500) # to change the size of all the images to 500x500 px. 

# path to training data
train_path = " " ''' GIVE THE DIRECTORY PATH HERE '''

# no.of.trees for Random Forests
num_trees = 100 

# bins for histogram
bins = 8

# train_test_split size
test_size = 0.10 # Train test split Train: 90% Test: 10%

# seed for reproducing same results
seed = 9


###################### Functions ##################################

# feature extraction technique 1: Hu Moments
def hu_feats(image):

    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # convert the image from BGR to gray for easy processing
    feature = cv2.HuMoments(cv2.moments(image)).flatten() # get the Hu moments using the openCV library

    return feature

# feature extraction technique 2: Haralick Texture features

def haralick_feats(image):

    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # convert the image to grayscale
    features = mahotas.features.haralick(image).mean(axis=0) # compute the haralick texture feature vector

    return features

# feature extraction technique 3: HOG (Histogram of Oriented Gradients)

def fd_hog(image):
    
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    features, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),
                    cells_per_block=(1, 1), visualise=True)
    
    return features

# feature extraction technique 4: Color Histograms

def fd_histogram(image, mask=None):

    # convert the image from BGR to HSV  format
    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    # compute the color histograms
    histograms  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])

    # normalize the histograms
    cv2.normalize(histograms, histograms)

    # return the histograms
    return histiograms.flatten()


# get the training labels
train_labels = os.listdir(train_path)

# sort the training labels
train_labels.sort()

# print(train_labels)

# empty lists to hold feature vectors and labels
global_features = []

labels = []
i, j = 0, 0
k = 0

# loop over the training data sub-folders
for training_name in train_labels:

    # join the training data path and each species training folder
    dir = os.path.join(train_path, training_name)

    # get the current training label
    current_label = training_name

    k = 1
    # loop over the images in each sub-folder
    contents = os.listdir(dir)

    for file in contents:
        # get the image file name
        file_dir = os.path.join(dir, file)

        # read the image and resize it to a fixed-size
        image = cv2.imread(file_dir)
        image = cv2.resize(image, (500,500))
